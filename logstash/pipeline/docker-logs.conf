# ============================================
# Logstash Pipeline 配置
# 用于接收 Filebeat 发送的 web-app 容器日志
# 功能：
#   1. 接收来自 Filebeat 的日志
#   2. 区分 JSON 应用日志和 Gunicorn 访问日志
#   3. 使用 Grok 解析不同类型的日志
#   4. 处理多行异常堆栈日志
#   5. 按日志级别分类（Info/Error）
# ============================================

input {
  # Beats 输入 - 接收 Filebeat 发送的日志
  beats {
    port => 5044
    type => "beats"
  }
}

filter {
  # ============================================
  # 1. 日志类型识别和初步处理
  # ============================================
  
  # 检测日志类型（应用 JSON 日志 vs Gunicorn 访问日志）
  if [log_type] == "application" {
    # 应用 JSON 日志 - Filebeat 已经解析
    
    mutate {
      add_field => { "[@metadata][log_format]" => "json_app" }
    }
    
  } else if [log_type] == "gunicorn_access" {
    # Gunicorn 访问日志 - 纯文本格式
    mutate {
      add_field => { "[@metadata][log_format]" => "gunicorn" }
    }
    
  } else {
    # 其他类型日志
    mutate {
      add_field => { "[@metadata][log_format]" => "other" }
    }
  }

  # ============================================
  # 2. JSON 应用日志处理（含异常堆栈）
  # ============================================
  
  if [@metadata][log_format] == "json_app" {
    
    # 处理异常堆栈日志（多行合并）
    # 异常日志包含 exception 对象，其中 stacktrace 是数组
    if [exception][stacktrace] {
      
      # 将堆栈跟踪数组合并为单个字符串
      ruby {
        code => '
          stacktrace = event.get("[exception][stacktrace]")
          if stacktrace.is_a?(Array)
            # 合并所有堆栈行
            full_stacktrace = stacktrace.join("")
            event.set("[exception][full_stacktrace]", full_stacktrace)
            
            # 提取异常关键信息
            event.set("[exception][has_stacktrace]", true)
            
            # 统计堆栈深度
            event.set("[exception][stack_depth]", stacktrace.length)
          end
        '
      }
      
      # 使用 Grok 提取堆栈中的文件和行号信息
      grok {
        match => {
          "[exception][full_stacktrace]" => [
            'File "%{DATA:exception_file}", line %{NUMBER:exception_line}',
            'at %{DATA:exception_class}\.%{DATA:exception_method}\(%{DATA:exception_file}:%{NUMBER:exception_line}\)'
          ]
        }
        tag_on_failure => []
        overwrite => ["exception_file", "exception_line"]
      }
      
      # 标记为异常日志
      mutate {
        add_tag => ["has_exception", "multiline_log"]
        add_field => { "severity" => "ERROR" }
      }
    }
    
    # 使用 Grok 提取和验证日志级别
    grok {
      match => {
        "level" => "^(?<log_level>DEBUG|INFO|WARN|WARNING|ERROR|FATAL|CRITICAL)$"
      }
      tag_on_failure => []
    }
    
    # 如果 Grok 提取失败，使用原始 level 字段
    if ![log_level] and [level] {
      mutate {
        add_field => { "log_level" => "%{level}" }
      }
    }
    
    # 日志级别分类（Info vs Error）
    if [log_level] in ["ERROR", "FATAL", "CRITICAL"] {
      mutate {
        add_tag => ["error_log"]
      }
      if ![severity] {
        mutate {
          add_field => { "severity" => "ERROR" }
        }
      }
    } else if [log_level] in ["WARN", "WARNING"] {
      mutate {
        add_tag => ["warning_log"]
      }
      if ![severity] {
        mutate {
          add_field => { "severity" => "WARNING" }
        }
      }
    } else {
      mutate {
        add_tag => ["info_log"]
      }
      if ![severity] {
        mutate {
          add_field => { "severity" => "INFO" }
        }
      }
    }
    
    # 使用 Grok 提取 HTTP 相关信息（如果存在）
    if [http_method] {
      grok {
        match => {
          "http_method" => "^(?<http_verb>GET|POST|PUT|DELETE|PATCH|HEAD|OPTIONS)$"
        }
        tag_on_failure => []
      }
      
      # 提取 URL 路径信息
      if [url] {
        grok {
          match => {
            "url" => "https?://[^/]+(?<url_path>/[^\?]*)(\?%{GREEDYDATA:url_params})?"
          }
          tag_on_failure => []
        }
      }
      
      # HTTP 状态码分类
      if [status_code] {
        if [status_code] >= 500 {
          mutate {
            add_tag => ["http_5xx", "server_error"]
            add_field => { "http_status_category" => "5xx Server Error" }
          }
        } else if [status_code] >= 400 {
          mutate {
            add_tag => ["http_4xx", "client_error"]
            add_field => { "http_status_category" => "4xx Client Error" }
          }
        } else if [status_code] >= 300 {
          mutate {
            add_tag => ["http_3xx", "redirect"]
            add_field => { "http_status_category" => "3xx Redirect" }
          }
        } else if [status_code] >= 200 {
          mutate {
            add_tag => ["http_2xx", "success"]
            add_field => { "http_status_category" => "2xx Success" }
          }
        }
        
        # 转换状态码为整数
        mutate {
          convert => { "status_code" => "integer" }
        }
      }
      
      # 响应时间分类（性能监控）
      if [response_time_ms] {
        mutate {
          convert => { "response_time_ms" => "float" }
        }
        
        # 慢请求检测（响应时间 > 1000ms）
        if [response_time_ms] >= 1000 {
          mutate {
            add_tag => ["slow_request"]
          }
        }
      }
    }
    
    # 解析时间戳
    if [timestamp] {
      date {
        match => [ 
          "timestamp", 
          "ISO8601",
          "yyyy-MM-dd'T'HH:mm:ss.SSSSSSSSS'Z'",
          "yyyy-MM-dd'T'HH:mm:ss.SSSSSS'Z'",
          "yyyy-MM-dd'T'HH:mm:ss.SSS'Z'",
          "yyyy-MM-dd'T'HH:mm:ss'Z'"
        ]
        target => "@timestamp"
        tag_on_failure => ["_dateparsefailure"]
      }
    }
  }

  # ============================================
  # 3. Gunicorn 访问日志处理
  # ============================================
  
  if [@metadata][log_format] == "gunicorn" {
    
    # Gunicorn 访问日志格式:
    # 127.0.0.1 - - [06/Dec/2025:10:30:45 +0000] "GET /api/user/1 HTTP/1.1" 200 150
    
    # 使用 Grok 解析访问日志
    grok {
      match => {
        "message" => '%{IPORHOST:client_ip} - - \[%{HTTPDATE:access_timestamp}\] "%{WORD:http_method} %{URIPATHPARAM:url_path} HTTP/%{NUMBER:http_version}" %{NUMBER:status_code} %{NUMBER:response_bytes}'
      }
      tag_on_failure => ["_grokparsefailure_gunicorn"]
    }
    
    # 如果 Grok 成功
    if "_grokparsefailure_gunicorn" not in [tags] {
      
      # 解析时间戳
      date {
        match => [ "access_timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
        target => "@timestamp"
        tag_on_failure => ["_dateparsefailure_gunicorn"]
      }
      
      # 转换数字字段
      mutate {
        convert => {
          "status_code" => "integer"
          "response_bytes" => "integer"
        }
      }
      
      # HTTP 状态码分类
      if [status_code] >= 500 {
        mutate {
          add_tag => ["http_5xx", "server_error"]
          add_field => { 
            "severity" => "ERROR"
            "log_level" => "ERROR"
          }
        }
      } else if [status_code] >= 400 {
        mutate {
          add_tag => ["http_4xx", "client_error"]
          add_field => { 
            "severity" => "WARNING"
            "log_level" => "WARNING"
          }
        }
      } else {
        mutate {
          add_tag => ["http_success"]
          add_field => { 
            "severity" => "INFO"
            "log_level" => "INFO"
          }
        }
      }
      
      # 提取 URL 组件
      grok {
        match => {
          "url_path" => "^(?<url_base>/[^/]+)(/(?<url_resource>.*))?$"
        }
        tag_on_failure => []
      }
    }
  }

  # ============================================
  # 4. 通用字段处理
  # ============================================
  
  # 添加容器信息标签
  if [container][name] {
    mutate {
      add_field => { "service_name" => "%{[container][name]}" }
    }
  }
  
  # 添加处理时间戳
  ruby {
    code => "event.set('processed_at', Time.now.utc.iso8601)"
  }
  
  # 移除冗余字段
  mutate {
    remove_field => [
      "@version",
      "log_type",
      "access_timestamp"
    ]
  }
}


output {
  # ============================================
  # 输出到 Elasticsearch - 按日志类型和级别分索引
  # ============================================
  
  # 应用日志（JSON 格式）
  if [@metadata][log_format] == "json_app" {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      # 根据日志级别分索引
      index => "webapp-logs-%{severity}-%{+YYYY.MM.dd}"
      document_id => "%{[@metadata][fingerprint]}"
    }
  }
  
  # Gunicorn 访问日志
  else if [@metadata][log_format] == "gunicorn" {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "webapp-access-%{+YYYY.MM.dd}"
      document_id => "%{[@metadata][fingerprint]}"
    }
  }
  
  # 其他日志
  else {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "webapp-other-%{+YYYY.MM.dd}"
      document_id => "%{[@metadata][fingerprint]}"
    }
  }
}
